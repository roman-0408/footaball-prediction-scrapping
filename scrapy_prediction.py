# -*- coding: utf-8 -*-
"""scrapy_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-UbCHmxO1Id9J4HfTmpv9T-12AE8h3Q4
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import json
from pandas.io.json import json_normalize
import datetime

### ALL PREDICTIONS 

url = "https://www.forebet.com/en/football-predictions"
headers = {'User-Agent': 
           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}

pageTree = requests.get(url, headers=headers)
pageSoup = BeautifulSoup(pageTree.content, 'html.parser')
table_tag = pageSoup.find_all("td", {"class": "contentmiddle"})

games = pd.DataFrame(columns=["League","Date", "Time", "HomeTeam", "AwayTeam", "Proba_1 - HT Win", "Proba_X - Draw", "Proba_2 - AT Win", 
                              "ResultForecast", "Proba_Result", "ScoreGame", "AvgGoals", "Weather", "Odds"], index=range(len(table_tag[0].find_all("span", {"class": "shortTag"}))))

### first games 
for i in range(len(table_tag[0].find_all("span", {"class": "shortTag"}))):
  games["League"].loc[i]=table_tag[0].find_all("span", {"class": "shortTag"})[i].text
  games["Date"].loc[i]=table_tag[0].find_all("span", {"class": "date_bah"})[i].text.split()[0]
  games["Time"].loc[i]=table_tag[0].find_all("span", {"class": "date_bah"})[i].text.split()[1]
  games["HomeTeam"].loc[i]=table_tag[0].find_all("span", {"class": "homeTeam"})[i].text
  games["AwayTeam"].loc[i]=table_tag[0].find_all("span", {"class": "awayTeam"})[i].text
  games["ResultForecast"].loc[i]=table_tag[0].find_all("td", {"class": ["predict", "predict_no", "predict_y"]})[i].text
  games["Odds"].loc[i]=table_tag[0].find_all("span", {"class": ["odds2"]})[i].text

for i in range(len(table_tag[0].find_all("span", {"class": "shortTag"}))):
  table=table_tag[0].find_all("tr", {"class": ["tr_0", "tr_1"]})[i].find_all("td")
  for i in range(len(table_tag[0].find_all("tr", {"class": ["tr_0", "tr_1"]})[0].find_all("td", {"class": ["ad-td"]}))):
    table.remove(table_tag[0].find_all("tr", {"class": ["tr_0", "tr_1"]})[0].find_all("td", {"class": ["ad-td"]})[i])
  l=1
  games["Proba_1 - HT Win"].loc[i]=table[l].text
  l+=1
  games["Proba_X - Draw"].loc[i]=table[l].text
  l+=1
  games["Proba_2 - AT Win"].loc[i]=table[l].text
  l+=8
  games["Proba_Result"].loc[i]=np.where(games["ResultForecast"].loc[i]=='1', games["Proba_1 - HT Win"].loc[i], np.where(games["ResultForecast"].loc[i]=="X", games["Proba_X - Draw"].loc[i],
                                                                                                                        games["Proba_2 - AT Win"].loc[i]))

for i in range(len(table_tag[0].find_all("span", {"class": "shortTag"}))):
    games["ScoreGame"].loc[i]=table_tag[0].find_all("tr", {"class": ["tr_0", "tr_1"]})[i].find_all("td", {"class": ["tabonly"]})[0].text
    games["AvgGoals"].loc[i]=table_tag[0].find_all("tr", {"class": ["tr_0", "tr_1"]})[i].find_all("td", {"class": ["tabonly"]})[1].text
    games["Weather"].loc[i]=table_tag[0].find_all("tr", {"class": ["tr_0", "tr_1"]})[i].find_all("td", {"class": ["tabonly"]})[2].text

## more games

try:
  for l in range(1, 10):
    url = "https://www.forebet.com/scripts/getrs.php?ln=en&tp=1x2&in=1"+str(l)
    headers = {'User-Agent': 
              'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}

    pageTree = requests.get(url, headers=headers)
    pageSoup = BeautifulSoup(pageTree.content, 'html.parser')

    games2 = pd.DataFrame(columns=["League","Date", "Time", "HomeTeam", "AwayTeam", "Proba_1 - HT Win", "Proba_X - Draw", "Proba_2 - AT Win", 
                                  "ResultForecast", "Proba_Result", "ScoreGame", "AvgGoals", "Weather", "Odds"], index=range(len(json.loads(pageSoup.get_text()))))

    for i in range(len(json.loads(pageSoup.get_text()))):
      games2["League"].loc[i]=json_normalize(json.loads(pageSoup.get_text())[i])["short_tag"][0]
      games2["Date"].loc[i]=json_normalize(json.loads(pageSoup.get_text())[i])["DATE"][0]
      games2["Time"].loc[i]=json_normalize(json.loads(pageSoup.get_text())[i])["DATE_BAH"][0].split()[1]
      games2["HomeTeam"].loc[i]=json_normalize(json.loads(pageSoup.get_text())[i])["HOST_NAME"][0]
      games2["AwayTeam"].loc[i]=json_normalize(json.loads(pageSoup.get_text())[i])["GUEST_NAME"][0]
      games2["Proba_1 - HT Win"].loc[i]=int(json_normalize(json.loads(pageSoup.get_text())[i])["Pred_1"][0])
      games2["Proba_X - Draw"].loc[i]=int(json_normalize(json.loads(pageSoup.get_text())[i])["Pred_X"][0])
      games2["Proba_2 - AT Win"].loc[i]=int(json_normalize(json.loads(pageSoup.get_text())[i])["Pred_2"][0])
      games2["ResultForecast"].loc[i]=np.where((games2["Proba_1 - HT Win"].loc[i]>games2["Proba_X - Draw"].loc[i]) and (games2["Proba_1 - HT Win"].loc[i]>games2["Proba_2 - AT Win"].loc[i]),
                                              1, np.where((games2["Proba_X - Draw"].loc[i]>games2["Proba_1 - HT Win"].loc[i]) and (games2["Proba_X - Draw"].loc[i]>games2["Proba_2 - AT Win"].loc[i]),"X", 2))
      games2["Proba_Result"].loc[i]=np.where(games2["ResultForecast"].loc[i]=="1", games2["Proba_1 - HT Win"].loc[i], np.where(games2["ResultForecast"].loc[i]=="X", games2["Proba_X - Draw"].loc[i],
                                                                                                                          games2["Proba_2 - AT Win"].loc[i]))
      games2["ScoreGame"].loc[i]=json_normalize(json.loads(pageSoup.get_text())[i])["host_sc_pr"][0]+" - "+json_normalize(json.loads(pageSoup.get_text())[i])["guest_sc_pr"][0]
      games2["AvgGoals"].loc[i]=json_normalize(json.loads(pageSoup.get_text())[i])["goalsavg"][0]
      games2["Weather"].loc[i]=json_normalize(json.loads(pageSoup.get_text())[i])["weather_high"][0]
      games2["Odds"].loc[i]=json_normalize(json.loads(pageSoup.get_text())[i])["best_odd"][0]
    
    games=pd.concat([games, games2], ignore_index=True)
except:
  pass

games=games.replace([None], " - ")
games["Date"]=pd.to_datetime(games["Date"])


### TOMORROW PREDICT

games=pd.read_html("https://www.forebet.com/en/football-tips-and-predictions-for-tomorrow")[4].drop([0, 1, 2, 10, 23, 57, 93, 129])
games1=games[0].str.split(pat="  ", expand=True)
games1=pd.concat([games1, games1[3].str.split(expand=True)],1).drop([3, 4],1)
games1.columns=["League", "HomeTeam", "AwayTeam", "Date", "Time"]
games=games.drop([0, 9, 10, 11, 12], 1)
games.columns=["Proba_1 - HT Win", "Proba_X - Draw", "Proba_2 - AT Win", "Result_Forecast", "Score_Game", "AvgGoals", "Weather", "Odds"]
games=pd.concat([games1, games], 1)
games["Proba_Result"]=np.where(games["Result_Forecast"]=="1", games["Proba_1 - HT Win"], np.where(games["Result_Forecast"]=="X", games["Proba_X - Draw"], games["Proba_2 - AT Win"]))


### TODAY PREDICT

games=pd.read_html("https://www.forebet.com/en/football-tips-and-predictions-for-today")[4].drop([0, 1, 2, 10, 23])
games1=games[0].str.split(pat="  ", expand=True)
games1=pd.concat([games1, games1[3].str.split(expand=True)],1).drop([3,4],1)
games1.columns=["League", "HomeTeam", "AwayTeam", "Date", "Time"]
games2=games[8].str.split(pat=" ", expand=True)
games2=games2.rename(columns={0: "Odds"})
games1=pd.concat([games1, games2["Odds"]], 1)
games=games.drop([0,8,9,10,11], 1)
games.columns=["Proba_1 - HT Win", "Proba_X - Draw", "Proba_2 - AT Win", "Result_Forecast", "Score_Game", "AvgGoals", "Weather"]
games=pd.concat([games1, games], 1)
games["Proba_Result"]=np.where(games["Result_Forecast"]=="1", games["Proba_1 - HT Win"], np.where(games["Result_Forecast"]=="X", games["Proba_X - Draw"], games["Proba_2 - AT Win"]))